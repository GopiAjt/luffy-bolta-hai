import re
import json
import requests
from typing import List, Dict
import os
from dotenv import load_dotenv
import google.generativeai as genai
import logging

# Set up logging
logger = logging.getLogger(__name__)

# Load environment variables from .env
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("Set GOOGLE_API_KEY or GEMINI_API_KEY in your .env file")

genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-2.0-flash")


def parse_ass_dialogues(ass_path: str) -> List[Dict]:
    dialogues = []
    dialogue_re = re.compile(
        r"Dialogue: [^,]*,([^,]*),([^,]*),[^,]*,[^,]*,[^,]*,[^,]*,[^,]*,(.*)")
    with open(ass_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.startswith('Dialogue:'):
                match = dialogue_re.match(line)
                if match:
                    start, end, text = match.groups()
                    text = re.sub(
                        r'{.*?}', '', text).replace('\n', ' ').strip()
                    dialogues.append(
                        {'start': start.strip(), 'end': end.strip(), 'text': text})
    return dialogues


def group_dialogues(dialogues: List[Dict]) -> List[Dict]:
    groups = []
    current = None
    for dlg in dialogues:
        if not current:
            current = {'start': dlg['start'],
                       'end': dlg['end'], 'text': dlg['text']}
        else:
            if re.search(r'[.!?]$', current['text']) or (dlg['text'].lower().startswith('but') or dlg['text'].lower().startswith('and')):
                groups.append(current)
                current = {'start': dlg['start'],
                           'end': dlg['end'], 'text': dlg['text']}
            else:
                current['end'] = dlg['end']
                current['text'] += ' ' + dlg['text']
    if current:
        groups.append(current)
    return groups


def get_gemini_image_description(start, end, summary):
    prompt = (
        "You are an expert video content designer. Your task is to map subtitle segments to suggested background image descriptions, structured in JSON.\n"
        f"Subtitle segment:\n\"{summary}\"\n\n"
        f"Generate a JSON object with:\n- start_time: \"{start}\"\n- end_time: \"{end}\"\n- summary: short subtitle text\n- image_description: concise prompt for a slide background image\n\n"
        "Schema:\n{\"start_time\": \"string\", \"end_time\": \"string\", \"summary\": \"string\", \"image_description\": \"string\"}"
    )
    try:
        response = model.generate_content(prompt)
        if response.text:
            logger.info(f"Gemini raw response: {response.text}")
            import json as _json
            text = response.text.strip()
            if text.startswith("```"):
                # Remove first line (```json or ```)
                text = text.split('\n', 1)[-1]
                if text.endswith("```"):
                    text = text.rsplit('```', 1)[0]
                text = text.strip()
            try:
                return _json.loads(text)
            except Exception as parse_err:
                logger.error(
                    f"Failed to parse Gemini response as JSON: {response.text}")
                raise
        else:
            logger.error("No text generated by Gemini API")
            raise ValueError("No text generated by Gemini API")
    except Exception as e:
        logger.error(f"Error from Gemini API: {str(e)}")
        raise


def filter_irrelevant_summaries(slides):
    # List of phrases that indicate a slide should be merged with the previous
    skip_phrases = [
        "get this.", "it's both.", "trick question.", "but here's the question.",
        "but that's not all.", "trick question", "get this", "it's both", "but here's the question", "but that's not all"
    ]
    filtered = []
    for slide in slides:
        summary = slide.get("summary", "").strip().lower()
        # If summary is in skip_phrases, merge interval with previous
        if any(phrase in summary for phrase in skip_phrases):
            if filtered:
                # Extend the end_time of the previous slide
                filtered[-1]["end_time"] = slide["end_time"]
        else:
            filtered.append(slide)
    return filtered


def generate_gemini_image_slides(ass_path: str, out_path: str) -> str:
    # Read and group all dialogues as before
    dialogues = parse_ass_dialogues(ass_path)
    groups = group_dialogues(dialogues)
    # Prepare a single prompt with all grouped segments
    prompt_segments = []
    for group in groups:
        prompt_segments.append(
            f"[{group['start']} - {group['end']}] {group['text']}")
    all_segments = "\n".join(prompt_segments)
    prompt = (
        "You are an expert video content designer. Your task is to map subtitle segments to suggested background image descriptions, structured in JSON.\n"
        f"Here are the grouped subtitle segments for a short video:\n{all_segments}\n\n"
        "Generate a JSON array where each object has:\n- start_time (string, e.g. '0:00:00')\n- end_time\n- summary (short subtitle text)\n- image_description (concise prompt for a slide background image)\n\n"
        "Only create a new object if the segment contains meaningful, content-rich, or One Piece-specific narration.\n"
        "Do NOT create a new object for generic, transition, or filler lines (e.g., 'get this', 'trick question', 'but here\'s the question', 'it\'s both', 'wait', 'and', 'so', 'then', 'but that\'s not all', or any line with less than 4 words or that does not mention a One Piece concept or character).\n"
        "Instead, extend the previous object's end_time to cover these lines.\n"
        "Use the exact schema below.\n\nSchema:\n[\n  {\n    \"start_time\": \"string\",\n    \"end_time\": \"string\",\n    \"summary\": \"string\",\n    \"image_description\": \"string\"\n  }\n]"
    )
    try:
        response = model.generate_content(prompt)
        if response.text:
            logger.info(f"Gemini raw response: {response.text}")
            import json as _json
            text = response.text.strip()
            if text.startswith("```"):
                text = text.split('\n', 1)[-1]
                if text.endswith("```"):
                    text = text.rsplit('```', 1)[0]
                text = text.strip()
            try:
                slides = _json.loads(text)
                slides = filter_irrelevant_summaries(slides)
            except Exception as parse_err:
                logger.error(
                    f"Failed to parse Gemini response as JSON: {response.text}")
                raise
        else:
            logger.error("No text generated by Gemini API")
            raise ValueError("No text generated by Gemini API")
    except Exception as e:
        logger.error(f"Error from Gemini API: {str(e)}")
        raise
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(slides, f, indent=2)
    return out_path


def generate_image_slides(ass_path: str, out_path: str) -> str:
    """
    Backward-compatible alias for generate_gemini_image_slides.
    """
    return generate_gemini_image_slides(ass_path, out_path)
